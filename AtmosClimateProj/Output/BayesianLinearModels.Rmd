---
title: "Bayesian Linear Analysis"
author: "Megan Feddern"
date: "2023-04-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(nord)
library(tidyr)
library(lubridate)
library(readr)
library(stringr)
library(ggplot2)
library(cowplot)
library(Cairo)
library(MCMCvis)
library(HDInterval)
library(reshape2)
library(tidyverse)
library(dplyr)
library(rstan)
library(here)
library(PNWColors)
library(maps)       #basic mapping functions and some data
library(mapdata)    #some additional hires data
library(maptools)   #useful tools such as reading shapefiles
library(mapproj)
library(rgdal)
library(colorspace)
library(PBSmapping) #powerful mapping functions developed by Pacific Biological Station
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
```

Mapping Bakun Index locations
```{r map, include=FALSE}

here::i_am("AtmosClimateProj/Src/BayesianLinearModels.Rmd")
col<-pnw_palette("Sunset2",3,type="discrete")
col2<-pnw_palette("Sunset2",8,type="continuous")

bakunsites <- read.csv(here('AtmosClimateProj/data/physical/Bakun/MapLocations.csv'))
sites <- st_as_sf(data.frame(bakunsites[,1:2]), coords = c("longitude","latitude"), crs = 4326, 
agr = "constant")


world <- ne_countries(scale='medium',returnclass = 'sf')
class(world)

map <- ggplot(data = world) +
   annotate("rect",xmin = -117, xmax = -157, ymin = 51.5, ymax = 62, 
     fill = col[3], colour = col[3], size = 0.8, alpha=0.5) +
  annotate(geom = "text", x = -145, y = 55, label = "Gulf of Alaska", 
     fontface = "italic", color = "grey22", size = 4) +
  annotate("rect",xmin = -135, xmax = -115, ymin = 40.4401, ymax = 51.5, 
     fill = col[2], colour = col[2], size = 0.8, alpha=0.5) +
  annotate(geom = "text", x = -130, y = 45, 
    label = str_wrap("Northern California  Current", width = 5),
    fontface = "italic", color = "grey22", size = 4) +
   annotate("rect", xmin= -135, xmax = -115, ymin = 31.5, ymax = 40.4401, 
     fill = col[1], colour = col[1], size = 0.8, alpha=0.5) +
  annotate(geom = "text", x = -130, y = 36.5, 
    label = str_wrap("Southern California  Current", width = 5),
    fontface = "italic", color = "grey22", size = 4) +
  geom_point(x=-160, y = 45,size = 3, shape = 23, col = "black", fill = col2[5])+
  annotate(geom = "text", x = -152, y = 45, 
    label = str_wrap("Bakun Index Location", width = 12),
     color = "grey22", size = 4) +
  geom_sf(fill='grey95') +
  geom_sf(data = sites, size = 2, shape = 23, col = "black", fill = col2[5]) +
     coord_sf(xlim = c(-165, -114), ylim = c(31.5, 62.5), expand = FALSE)+
   scale_x_continuous(name = "") +
   scale_y_continuous(name = "") +
  theme(panel.background = element_rect(fill = "white"),
     panel.border = element_rect(fill = NA))


```

```{r map2}
map
```


## Combining Bakun Data
1) Import the Bakun upwelling data from each individual file associated with the 13 lat/long locations. Data versions are: 1˚ 6-hourly version

```{r combine, include=FALSE}

bakundat <-read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI246hr_d68d_e898_8529.csv'))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI276hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI306hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI336hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI366hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI396hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI426hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI456hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI486hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI516hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI546hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI576hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI606hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('AtmosClimateProj/data/physical/Bakun/erdUI616hr_d68d_e898_8529.csv')))
```

2) Extract yyyy-mm-ddThh:mm:ss from the 'time' column and add region indicator based on station ID and add a time period based on year

```{r dates, include=FALSE}
bakun <- bakundat%>%
add_column('Year'=as.numeric(format(as.Date(bakundat$time),"%Y")))%>%
add_column('Month'=as.numeric(format(as.Date(bakundat$time),"%m")))%>%
add_column("Day"=as.numeric(format(as.Date(bakundat$time),"%d")))

bakun_region <- bakun%>%
  filter(station_id=='33N'|station_id=='36N'|station_id=='39N')%>%
  mutate(region="Southern CC")%>%
bind_rows(bakun%>%
  filter(station_id=='42N'|station_id=='45N'|station_id=='48N'|station_id=='51N')%>%
  mutate(region="Northern CC"))%>%
bind_rows(bakun%>%
  filter(station_id=='54N'|station_id=='57N'|station_id=='60N')%>%
  mutate(region="GoA"))


```
3) Summarize across days and hours to get monthly means for region and year. If you revert to seasonal summaries return to here to summarise across dates without taking means of means. Adding standardized upwelling index
```{r summ, include=FALSE}
bakun_summ <- bakun_region%>%
  group_by(region, Year, Month) %>%
  summarise(monthly_mean = mean(na.omit(upwelling_index)), monthly_sd = sd(na.omit(upwelling_index)))%>%
  mutate(stand_Bakun = (monthly_mean-mean(monthly_mean))/sd(monthly_mean))

bakun_time <- bakun_summ%>%
  filter(Year>1963 & Year<1989)%>%
  mutate(period='1')%>%
bind_rows(bakun_summ%>%
  filter(Year>1989 & Year<2014)%>%
  mutate(period='2'))%>%
bind_rows(bakun_summ%>%
  filter(Year>2013)%>%
  mutate(period='3'))%>%
  mutate(era.region = if_else(region == "GoA"&period == 1, 1, 
                        if_else(region == "GoA"&period == 2, 2, 
                          if_else(region == "GoA"&period == 3, 3,
                            if_else(region == "Northern CC"&period == 1, 4,
                              if_else(region == "Northern CC"&period == 2, 5,
                                if_else(region == "Northern CC"&period == 3, 6,
                                   if_else(region == "Southern CC"&period == 1, 7,
                                      if_else(region == "Southern CC"&period == 2, 8,
                                        if_else(region == "Southern CC"&period == 3, 9, 10))))))))))
        
```
4) Import PDO data, standardize across teh 1967 - 2022 time period
```{r PDO, include=FALSE}
PDO <- read.csv(here('AtmosClimateProj/data/physical/PDO.csv'))%>%
  pivot_longer(!Year, names_to = "Month", values_to = "PDO")%>%
mutate(Month = as.integer(factor(Month, levels = c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"))))%>%
  filter(Year>1966)%>%
  mutate(stand_PDO = (PDO-mean(na.omit(PDO)))/sd(na.omit(PDO)))

```

X) Merging the standardized datasets into a single dataframe

```{r MERGE, include=FALSE}
climate <- bakun_time%>%
  merge(PDO, by=c('Month', 'Year'))
saveRDS(climate, file = here('AtmosClimateProj/Output/standat.rds'))

```

Run the STAN model outside of markdown file using "STANrun.R" which exports the posteriors so that the model does not run in markdown when you knit.

```{r STAN, include=FALSE}
posterior <- readRDS(here("AtmosClimateProj/Output/posteriors.rds"))
```
## STAN Model
Bayesian linear model with era specific intercept and slope and region specific slope,

$$Upwelling = \alpha_{e,r} + \beta_{e,r}*PDO +\sigma$$
where *e* is factor "era" corresponding to eras 1967 - 1988, 1989 - 2013, and 2014 - 2022 and *r* corresponds to regions Southern California Current (south of Mendocino), Northern California Current (Mendocino to Vancouver Island), and Gulf of Alaska (north of Vancover Island).

| Parameter     | Description | Prior     |
| :---        |    :----:   |          ---: |
| $\alpha_{e,r}$      | Era and region specific anomaly      |  $~ Normal(0,10)$   |
| $\beta_{e,r}$   | Upwelling-PDO relationship by era and region        | $~ Normal(0,10)$      |
| $\sigma$   | Combined observation and process error        | $~ Normal(0,10)[0,]$     |



## Monthly Mean Model 

Linear relationship between monthly PDO Index and monthly upwelling (Bakun 1˚ 6-hourly) for each era and each region estimated from a Bayesian regression model.

```{r linearpdo, echo=FALSE}
alphaP<-posterior[1:9,]%>%
  add_column(region = rep(c("GoA", "NCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),3))

scaled.anomaly<- c(rnorm(1000, alphaP$mean[1],alphaP$sd[1]),
                   rnorm(1000, alphaP$mean[2],alphaP$sd[2]),
                   rnorm(1000, alphaP$mean[3],alphaP$sd[3]),
                   rnorm(1000, alphaP$mean[4],alphaP$sd[4]),
                   rnorm(1000, alphaP$mean[5],alphaP$sd[5]),
                   rnorm(1000, alphaP$mean[6],alphaP$sd[6]),
                   rnorm(1000, alphaP$mean[7],alphaP$sd[7]),
                   rnorm(1000, alphaP$mean[8],alphaP$sd[8]),
                   rnorm(1000, alphaP$mean[9],alphaP$sd[9]))%>%
  bind_cols(period=rep(rep(c('1967 - 1988', '1989 - 2013', '2014 - 2022'), each = 1000),3),
            region = rep(rep(c("GoA", "NCC", "SCC"),each = 3000)))%>%
  rename(anomaly=...1)

ggplot(data = climate, aes(x = stand_Bakun, y = PDO,col=period)) +
    facet_wrap(.~region, ncol = 3, scales='free') +
  geom_point(size=0.75,aes(col=period)) +
  geom_smooth(method = "lm", se = FALSE, aes(col=as.factor(period))) +
  scale_x_continuous(name = "Upwelling (Bakun 1˚ 6-hourly)") +
  scale_color_manual(values =  col[1:3], labels=c('1967 - 1988', '1989 - 2013', '2014 - 2022'))+
  theme_bw()

```
 
Era specific intercepts across the entire region (Southern California Current to Gulf of Alaska) estimated from a Bayesian regression model

```{r intercept, echo=FALSE}
ggplot(scaled.anomaly, aes(x = anomaly, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 3, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Intercept (scaled anomaly)",
       y = "Posterior density")

```



## Winter Model (Nov - March)

Using monthly mean data through winter months (Nov - Mar) where data is standardized for the time period and season

```{r summWINTER, include=FALSE}

climate <- bakun_time%>%
  merge(PDO, by=c('Month', 'Year'))%>%
  filter(Month==11| Month==12|Month==1|Month==2|Month==3)%>%
  mutate(stand_PDO = (PDO-mean(na.omit(PDO)))/sd(na.omit(PDO)))%>%
  mutate(stand_Bakun = (monthly_mean-mean(monthly_mean))/sd(monthly_mean))
saveRDS(climate, file = here('AtmosClimateProj/Output/standat.rds'))

```

Linear relationship between monthly PDO Index and monthly upwelling (Bakun 1˚ 6-hourly) for each era and each region estimated from a Bayesian regression model using Winter Monthly Means (Nov-March).

```{r linearpdoWINTER, echo=FALSE}
posterior <- readRDS(here("AtmosClimateProj/Output/posteriors.winter.rds"))
alphaP<-alphaP<-posterior[1:9,]%>%
  add_column(region = rep(c("GoA", "NCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),3))

scaled.anomaly<- c(rnorm(1000, alphaP$mean[1],alphaP$sd[1]),
                   rnorm(1000, alphaP$mean[2],alphaP$sd[2]),
                   rnorm(1000, alphaP$mean[3],alphaP$sd[3]),
                   rnorm(1000, alphaP$mean[4],alphaP$sd[4]),
                   rnorm(1000, alphaP$mean[5],alphaP$sd[5]),
                   rnorm(1000, alphaP$mean[6],alphaP$sd[6]),
                   rnorm(1000, alphaP$mean[7],alphaP$sd[7]),
                   rnorm(1000, alphaP$mean[8],alphaP$sd[8]),
                   rnorm(1000, alphaP$mean[9],alphaP$sd[9]))%>%
  bind_cols(period=rep(rep(c('1967 - 1988', '1989 - 2013', '2014 - 2022'), each = 1000),3),
            region = rep(rep(c("GoA", "NCC", "SCC"),each = 3000)))%>%
  rename(anomaly=...1)

ggplot(data = climate, aes(x = stand_Bakun, y = PDO,col=period)) +
    facet_wrap(.~region, ncol = 3, scales='free') +
  geom_point(size=0.75,aes(col=period)) +
  geom_smooth(method = "lm", se = FALSE, aes(col=as.factor(period))) +
  scale_x_continuous(name = "Upwelling (Bakun 1˚ 6-hourly)") +
  scale_color_manual(values =  col[1:3], labels=c('1967 - 1988', '1989 - 2013', '2014 - 2022'))+
  theme_bw()

```

Era specific intercepts across the entire region (Southern California Current to Gulf of Alaska) estimated from a Bayesian regression model for winter months (Nov - March)

```{r interceptWINTER, echo=FALSE}
ggplot(scaled.anomaly, aes(x = anomaly, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 3, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Intercept (scaled anomaly)",
       y = "Posterior density")

```


## Spring Model (April - June)

Using monthly mean data through winter months (April - June) where data is standardized for the time period and season

```{r summSPRING, include=FALSE}

climate <- bakun_time%>%
  merge(PDO, by=c('Month', 'Year'))%>%
  filter(Month==4| Month==5|Month==6)%>%
  mutate(stand_PDO = (PDO-mean(na.omit(PDO)))/sd(na.omit(PDO)))%>%
  mutate(stand_Bakun = (monthly_mean-mean(monthly_mean))/sd(monthly_mean))
saveRDS(climate, file = here('AtmosClimateProj/Output/standat.rds'))

```

Linear relationship between monthly PDO Index and monthly upwelling (Bakun 1˚ 6-hourly) for each era and each region estimated from a Bayesian regression model using spring Monthly Means (April - June).

```{r linearpdoSPRING, echo=FALSE}
posterior <- readRDS(here("AtmosClimateProj/Output/posteriors.spring.rds"))
alphaP<-alphaP<-posterior[1:9,]%>%
  add_column(region = rep(c("GoA", "NCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),3))

scaled.anomaly<- c(rnorm(1000, alphaP$mean[1],alphaP$sd[1]),
                   rnorm(1000, alphaP$mean[2],alphaP$sd[2]),
                   rnorm(1000, alphaP$mean[3],alphaP$sd[3]),
                   rnorm(1000, alphaP$mean[4],alphaP$sd[4]),
                   rnorm(1000, alphaP$mean[5],alphaP$sd[5]),
                   rnorm(1000, alphaP$mean[6],alphaP$sd[6]),
                   rnorm(1000, alphaP$mean[7],alphaP$sd[7]),
                   rnorm(1000, alphaP$mean[8],alphaP$sd[8]),
                   rnorm(1000, alphaP$mean[9],alphaP$sd[9]))%>%
  bind_cols(period=rep(rep(c('1967 - 1988', '1989 - 2013', '2014 - 2022'), each = 1000),3),
            region = rep(rep(c("GoA", "NCC", "SCC"),each = 3000)))%>%
  rename(anomaly=...1)

ggplot(data = climate, aes(x = stand_Bakun, y = PDO,col=period)) +
    facet_wrap(.~region, ncol = 3, scales='free') +
  geom_point(size=0.75,aes(col=period)) +
  geom_smooth(method = "lm", se = FALSE, aes(col=as.factor(period))) +
  scale_x_continuous(name = "Upwelling (Bakun 1˚ 6-hourly)") +
  scale_color_manual(values =  col[1:3], labels=c('1967 - 1988', '1989 - 2013', '2014 - 2022'))+
  theme_bw()

```

Era specific intercepts across the entire region (Southern California Current to Gulf of Alaska) estimated from a Bayesian regression model for spring monthly means (April - June)

```{r interceptSPRING, echo=FALSE}
ggplot(scaled.anomaly, aes(x = anomaly, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 3, scales = "free") +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Intercept (scaled anomaly)",
       y = "Posterior density")

```


## Summer Model (July - August)

Using monthly mean data through winter months (July - August) where data is standardized for the time period and season

```{r summSUMMER, include=FALSE}

climate <- bakun_time%>%
  merge(PDO, by=c('Month', 'Year'))%>%
  filter(Month==7| Month==8)%>%
  mutate(stand_PDO = (PDO-mean(na.omit(PDO)))/sd(na.omit(PDO)))%>%
  mutate(stand_Bakun = (monthly_mean-mean(monthly_mean))/sd(monthly_mean))
saveRDS(climate, file = here('AtmosClimateProj/Output/standat.rds'))

```

Linear relationship between monthly PDO Index and monthly upwelling (Bakun 1˚ 6-hourly) for each era and each region estimated from a Bayesian regression model using Summer Monthly Means (July - August).

```{r linearpdoSUMMER, echo=FALSE}
posterior <- readRDS(here("AtmosClimateProj/Output/posteriors.summer.rds"))
alphaP<-alphaP<-posterior[1:9,]%>%
  add_column(region = rep(c("GoA", "NCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),3))

scaled.anomaly<- c(rnorm(1000, alphaP$mean[1],alphaP$sd[1]),
                   rnorm(1000, alphaP$mean[2],alphaP$sd[2]),
                   rnorm(1000, alphaP$mean[3],alphaP$sd[3]),
                   rnorm(1000, alphaP$mean[4],alphaP$sd[4]),
                   rnorm(1000, alphaP$mean[5],alphaP$sd[5]),
                   rnorm(1000, alphaP$mean[6],alphaP$sd[6]),
                   rnorm(1000, alphaP$mean[7],alphaP$sd[7]),
                   rnorm(1000, alphaP$mean[8],alphaP$sd[8]),
                   rnorm(1000, alphaP$mean[9],alphaP$sd[9]))%>%
  bind_cols(period=rep(rep(c('1967 - 1988', '1989 - 2013', '2014 - 2022'), each = 1000),3),
            region = rep(rep(c("GoA", "NCC", "SCC"),each = 3000)))%>%
  rename(anomaly=...1)

ggplot(data = climate, aes(x = stand_Bakun, y = PDO,col=period)) +
    facet_wrap(.~region, ncol = 3, scales='free') +
  geom_point(size=0.75,aes(col=period)) +
  geom_smooth(method = "lm", se = FALSE, aes(col=as.factor(period))) +
  scale_x_continuous(name = "Upwelling (Bakun 1˚ 6-hourly)") +
  scale_color_manual(values =  col[1:3], labels=c('1967 - 1988', '1989 - 2013', '2014 - 2022'))+
  theme_bw()

```

Era specific intercepts across the entire region (Southern California Current to Gulf of Alaska) estimated from a Bayesian regression model for summer months (July - August)

```{r interceptSUMMER, echo=FALSE}
ggplot(scaled.anomaly, aes(x = anomaly, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 3, scales = "free") +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Intercept (scaled anomaly)",
       y = "Posterior density")

```


## Questions / Thoughts

To Do: 

1) Examine Upwelling relationships with SLP, SSH, wind stress, and SST
Examine the relationship between SST and the same set of atmospheric variables (PDO, SLP, SSH, wind stress). Would we really expect different relationships with SLP given its reanalyses are what make up Bakun indices?

2) we could also compare these results to results with CUTI and BEUTI that use just the last two periods (CUTI and BEUTI account for more nuanced changes in cross and along shore wind; only data after 1988)

3) other approaches for standardizing?

4) *plankton case study* I think that this paper would be more compelling if it had some degree of biology. Maybe we could bring in some of the Zoop CalCofi data as a case study within the larger regional analysis and link these changing relationships to an ecosystem response - it would also be a nice thing to build our way up the food web with the salmon/groundfish part of the project and still take a foodweb wide view that was initially in the proposal. Are there are plankton datasets in the Southern California Current and/or GoA we could use?