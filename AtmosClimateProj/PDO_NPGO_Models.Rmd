---
title: "Bayesian Linear Analysis"
author: "Megan Feddern"
date: "2023-05-08"
output:
  html_document: 
    toc: true
    toc_depth: 4
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(nord)
library(tidyr)
library(lubridate)
library(readr)
library(stringr)
library(ggplot2)
library(cowplot)
library(Cairo)
library(MCMCvis)
library(HDInterval)
library(reshape2)
library(tidyverse)
library(dplyr)
library(rstan)
library(here)
library(PNWColors)
library(maps)       #basic mapping functions and some data
library(mapdata)    #some additional hires data
library(maptools)   #useful tools such as reading shapefiles
library(mapproj)
library(rgdal)
library(colorspace)
library(PBSmapping) #powerful mapping functions developed by Pacific Biological Station
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
library(loo)

```

**Changes since Meeting**
- Tested covariance of station 51N; included in GoA not northern CC
- PDO is unstandardized
- Upwelling is standardized across entire time period (1967 - 2022), within region and within season (for the seasonal models - annaual model is not)
- Tested model using seasonal averages instead of monthly means across season. *I think this is the better approach*
- Added a lagged year variable so the months of Nov and Dec are included with the correct Jan - Mar values for winter
-Added NPGO analysis
-Tested an era based model and compared to a no era model with looic to compare model performance
-Altered distributions, added SCC to the data according to the map

Mapping Bakun Index locations with the regions we have identified

```{r map, include=FALSE}

here::i_am("Output/BayesianLinearModels.Rmd")
col2<-pnw_palette("Sunset2",4,type="discrete")
col<-pnw_palette("Sunset2",3,type="discrete")
col3<-pnw_palette("Sunset2",8,type="continuous")

bakunsites <- read.csv(here('data/physical/Bakun/MapLocations.csv'))
sites <- st_as_sf(data.frame(bakunsites[,1:2]), coords = c("longitude","latitude"), crs = 4326, 
agr = "constant")


world <- ne_countries(scale='medium',returnclass = 'sf')
class(world)

map <- ggplot(data = world) +
   annotate("rect",xmin = -117, xmax = -157, ymin = 50.5, ymax = 62, 
     fill = col2[1], colour = col2[1], size = 0.8, alpha=0.5) +
  annotate(geom = "text", x = -145, y = 55, label = "Gulf of Alaska", 
     fontface = "italic", color = "grey22", size = 4) +
  
  annotate("rect",xmin = -140, xmax = -115, ymin = 40.4401, ymax = 50.5, 
     fill = col2[2], colour = col2[2], size = 0.8, alpha=0.5) +
  annotate(geom = "text", x = -134, y = 45, 
    label = str_wrap("Northern California  Current", width = 5),
    fontface = "italic", color = "grey22", size = 4) +
   
   annotate("rect", xmin= -140, xmax = -115, ymin = 34.4486, ymax = 40.4401, 
     fill = col2[4], colour = col2[4], size = 0.8, alpha=0.5) +
   annotate(geom = "text", x = -132, y = 37, 
    label = str_wrap("Central California  Current", width = 20),
    fontface = "italic", color = "grey22", size = 3.75) +
  
  annotate("rect", xmin= -140, xmax = -105, ymin = 22.1, ymax = 34.4486, 
     fill = col2[3], colour = col2[3], size = 0.8, alpha=0.5) +
  annotate(geom = "text", x = -129, y = 27, 
    label = str_wrap("Southern California  Current", width = 5),
    fontface = "italic", color = "grey22", size = 4) +
  
  geom_point(x=-160, y = 45,size = 3, shape = 23, col = "black", fill = col3[5])+
  annotate(geom = "text", x = -152, y = 45, 
    label = str_wrap("Bakun Index Location", width = 12),
     color = "grey22", size = 4) +
  geom_sf(fill='grey95') +
  geom_sf(data = sites, size = 2, shape = 23, col = "black", fill = col3[5]) +
     coord_sf(xlim = c(-165, -108), ylim = c(22, 62.5), expand = FALSE)+
   scale_x_continuous(name = "") +
   scale_y_continuous(name = "") +
  theme(panel.background = element_rect(fill = "white"),
     panel.border = element_rect(fill = NA))
map

```

```{r map2}
map
```


## Combining Bakun Data
1) Import the Bakun upwelling data from each individual file associated with the 13 lat/long locations. Data versions are: 1Ëš 6-hourly version

```{r combine, include=FALSE}

bakundat <-read.csv(here('data/physical/Bakun/erdUI246hr_d68d_e898_8529.csv'))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI276hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI306hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI336hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI366hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI396hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI426hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI456hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI486hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI516hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI546hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI576hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI606hr_d68d_e898_8529.csv')))%>%
  bind_rows(read.csv(here('data/physical/Bakun/erdUI616hr_d68d_e898_8529.csv')))
```


2) Extract yyyy-mm-ddThh:mm:ss from the 'time' column and add region indicator based on station ID and add a time period based on year

```{r dates, include=FALSE}
bakun <- bakundat%>%
add_column('Year'=as.numeric(format(as.Date(bakundat$time),"%Y")))%>%
add_column('Month'=as.numeric(format(as.Date(bakundat$time),"%m")))%>%
add_column("Day"=as.numeric(format(as.Date(bakundat$time),"%d")))

bakun_region <- bakun%>%
  filter(station_id=='36N'|station_id=='39N')%>%
  mutate(region="Central CC")%>%
bind_rows(bakun%>%
  filter(station_id=='33N'|station_id=='30N'|station_id=='27N'|station_id=='24N')%>%
  mutate(region="Southern CC"))%>%
bind_rows(bakun%>%
  filter(station_id=='42N'|station_id=='45N'|station_id=='48N')%>%
  mutate(region="Northern CC"))%>%
bind_rows(bakun%>%
  filter(station_id=='51N'|station_id=='54N'|station_id=='57N'|station_id=='60N')%>%
  mutate(region="GoA"))


```


3) Summarize across days and hours to get monthly means for region and year. If you revert to seasonal summaries return to here to summarise across dates without taking means of means. Adding standardized upwelling index - upwelling is standardized across the entirety of the time period, but within region and space. **Note** because of the standardization positive values are above average for a given region and season for a year (cannot be interpreted as downwelling versus upwelling)

```{r summ, include=FALSE}
bakun_season <- bakun_region%>%
  filter(Month==12|Month==11|Month==1|Month==2|Month==3)%>%
  mutate(season="Winter")%>%
bind_rows(bakun_region%>%
  filter(Month==4|Month==5|Month==6)%>%
  mutate(season="Spring"))%>%
bind_rows(bakun_region%>%
  filter(Month==7|Month==8)%>%
  mutate(season="Summer"))%>%
mutate(Year_lag = if_else(Month == 11|Month ==12, Year+1, Year))


bakun_summ_season2 <- bakun_season%>%  
  group_by(season, region) %>%
  summarise(seasonal_mean = mean(na.omit(upwelling_index)), seasonal_sd =sd(na.omit(upwelling_index)))

bakun_summ_annual2 <- bakun_season%>%  
  group_by(region) %>%
  summarise(yearly_mean = mean(na.omit(upwelling_index)), yearly_sd =sd(na.omit(upwelling_index)))

bakun_summ_annual <- bakun_season%>%
  group_by(region, Year_lag) %>%
  summarise(annual_mean = mean(na.omit(upwelling_index)))%>%
  ungroup()%>%
  right_join(bakun_summ_annual2, by = c( 'region'))%>%
  mutate(stand_bakun_annual = (annual_mean-yearly_mean)/yearly_sd)%>%
  select(Year_lag, region,stand_bakun_annual)

bakun_summ_seasonal <- bakun_season%>%
  group_by(region, Year_lag,  season) %>%
  summarise(season_mean = mean(na.omit(upwelling_index)))%>%
  ungroup()%>%
  right_join(bakun_summ_season2, by = c('season', 'region'))%>%
  mutate(stand_bakun_seasonally = (season_mean-seasonal_mean)/seasonal_sd)%>%
  select(season,Year_lag, region,stand_bakun_seasonally)

bakun_summ<- bakun_season%>%
  group_by(Month, region, Year_lag) %>%
  summarise(monthly_mean = mean(na.omit(upwelling_index)))%>%
  mutate(stand_bakun_annually = (monthly_mean-mean(na.omit(monthly_mean)))/sd(na.omit(monthly_mean)))%>%
  mutate(season=if_else(Month == 11|Month ==12|Month ==1|Month ==2|Month ==3, "Winter",
                        if_else(Month ==4|Month ==5|Month ==6, "Spring",
                                if_else(Month ==7|Month ==8, "Summer", "Autumn"))))%>%
  right_join(bakun_summ_season2, by = c('region', 'season'))%>%
  mutate(stand_bakun_monthly = (monthly_mean-seasonal_mean)/seasonal_sd)%>%
  left_join(bakun_summ_seasonal)%>%
  left_join(bakun_summ_annual)


bakun_time <-bakun_summ%>%
  filter(Year_lag>1963 & Year_lag<1989)%>%
  mutate(period='1')%>%
bind_rows(bakun_summ%>%
  filter(Year_lag>1989 & Year_lag<2014)%>%
  mutate(period='2'))%>%
bind_rows(bakun_summ%>%
  filter(Year_lag>2013)%>%
  mutate(period='3'))%>%
  mutate(era.region = if_else(region == "GoA"&period == 1, 1, 
                        if_else(region == "GoA"&period == 2, 2, 
                          if_else(region == "GoA"&period == 3, 3,
                            if_else(region == "Northern CC"&period == 1, 4,
                              if_else(region == "Northern CC"&period == 2, 5,
                                if_else(region == "Northern CC"&period == 3, 6,
                                   if_else(region == "Central CC"&period == 1, 7,
                                      if_else(region == "Central CC"&period == 2, 8,
                                        if_else(region == "Central CC"&period == 3, 9, 
                                          if_else(region == "Southern CC"&period == 1, 10,
                                            if_else(region == "Southern CC"&period == 2, 11,
                                              if_else(region == "Southern CC"&period == 3, 12,
                                                  13)))))))))))))

```


4) Import PDO and NPGO data. Label months by a season factor. NOT standardized in this version - **Note** PDO CAN be interpreted as positive or negative BUT this is the data from the website so it has been detrended.

```{r PDO, include=FALSE}

PDO <- read.csv(here('data/physical/PDO.csv'))%>%
  pivot_longer(!Year, names_to = "Month", values_to = "PDO")%>%
mutate(Month = as.integer(factor(Month, levels = c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"))))%>%
  filter(Year>1965)%>%
  mutate(Year_lag = if_else(Month == 11|Month ==12, Year+1, Year))

PDO_seasonal <-  PDO%>%
  filter(Month==12|Month==11|Month==1|Month==2|Month==3)%>%
  mutate(season="Winter")%>%
bind_rows(PDO%>%
  filter(Month==4|Month==5|Month==6)%>%
  mutate(season="Spring"))%>%
bind_rows(PDO%>%
  filter(Month==7|Month==8)%>%
  mutate(season="Summer"))%>%
  mutate(Year_lag = if_else(Month == 11|Month ==12, Year+1, Year))%>%
  group_by(Year_lag, season)%>%
  summarise(seasonal_PDO = mean(PDO))


PDO_annual <-  PDO%>%
  group_by(Year_lag)%>%
  summarise(annual_PDO = mean(PDO))

NPGO <- read.csv(here('data/physical/NPGO.csv'))%>%
  filter(Year>1965)%>%
  mutate(Year_lag = if_else(Month == 11|Month ==12, Year+1, Year))

NPGO_seasonal <-  NPGO%>%
  filter(Month==12|Month==11|Month==1|Month==2|Month==3)%>%
  mutate(season="Winter")%>%
bind_rows(NPGO%>%
  filter(Month==4|Month==5|Month==6)%>%
  mutate(season="Spring"))%>%
bind_rows(NPGO%>%
  filter(Month==7|Month==8)%>%
  mutate(season="Summer"))%>%
  mutate(Year_lag = if_else(Month == 11|Month ==12, Year+1, Year))%>%
  group_by(Year_lag, season)%>%
  summarise(seasonal_NPGO = mean(NPGO))


NPGO_annual <-  NPGO%>%
  group_by(Year_lag)%>%
  summarise(annual_NPGO = mean(NPGO))




```

X) Merging the standardized datasets into a single dataframe and assigning levels

```{r MERGE, include=FALSE}
climate_dat <- bakun_time%>%
  merge(PDO, by=c('Month', 'Year_lag'))%>%
  merge(PDO_annual, by=c('Year_lag'))%>%
  merge(PDO_seasonal, by=c('season', 'Year_lag'))%>%
  left_join(NPGO, by=c('Month', 'Year_lag'))%>%
  left_join(NPGO_annual, by=c('Year_lag'))%>%
  left_join(NPGO_seasonal, by=c('season', 'Year_lag'))
saveRDS(climate_dat, file = here('Output/standat.rds'))


```

Run the STAN model outside of markdown file using "STANrun.R" which exports the posteriors so that the model does not run in markdown when you knit.



## STAN Model
Bayesian linear model with era specific intercept and slope and region specific slope,

$$Upwelling = \alpha_{e,r} + \beta_{e,r}*PDO +\sigma$$
where *e* is factor "era" corresponding to eras 1967 - 1988, 1989 - 2013, and 2014 - 2022 and *r* corresponds to regions Southern California Current (south of Mendocino), Northern California Current (Mendocino to Vancouver Island), and Gulf of Alaska (north of Vancover Island).

| Parameter     | Description | Prior     |
| :---        |    :----:   |          ---: |
| $\alpha_{e,r}$      | Era and region specific anomaly      |  $~ Normal(0,10)$   |
| $\beta_{e,r}$   | Upwelling-PDO relationship by era and region        | $~ Normal(0,10)$      |
| $\sigma$   | Combined observation and process error        | $~ Normal(0,10)[0,]$     |


#PDO - Upwelling relationship analyses

## Seasonal Mean Models

These results utilize seasonal averagers rather than monthly means within a season. May be better for identifying trends that are not spuriously seasonal (i.e. changes in a given month) but tradeoff is less data and may miss some interesting dynamics as a result

### Annual Model

```{r seasonalANNUAL, echo=FALSE}
annual <- climate_dat%>%
  select(Year_lag, region, season, seasonal_mean, stand_bakun_annual,period, era.region,annual_PDO)%>%
    distinct()%>%
  filter(Year_lag<2023)

N <- length(annual$period)
NP <- 12
P<- as.numeric(as.factor(annual$era.region))
P2 <-as.numeric(as.factor(annual$region))
K <- 1
x <- data.frame(annual$stand_bakun_annual)
y<-annual$annual_PDO

data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P2, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)

warmups <- 1000
total_iterations <- 3000
max_treedepth <-  10
n_chains <-  3
n_cores <- 4
adapt_delta <- 0.95

bhfit.pdo.annual  <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))

data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)

bhfit.pdo.annual.era <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))


posterior<-data.frame(summary(bhfit.pdo.annual.era, prob=c(0.025, 0.25,0.75, 0.975, 0.1, 0.9))$summary)

alphaP<-posterior[1:12,]%>%
  add_column(region = rep(c("GoA", "NCC","CCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))

betaP<-posterior[13:24,]%>%
  add_column(region = rep(c("GoA", "NCC","CCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))
n<- 1000
scaled.anomaly <- NULL
for(i in 1:NP){
tempalpha <- rnorm(n, alphaP$mean[i],alphaP$sd[i])
tempbeta <- rnorm(n, betaP$mean[i],betaP$sd[i])
scaled.anomaly <-rbind(scaled.anomaly,cbind(tempalpha, tempbeta))
}

scaled.anomaly<- scaled.anomaly%>%
  bind_cols(period=rep(rep(c('1967 - 1988', '1989 - 2013', '2014 - 2022'), each = 1000),4),
            region = rep(rep(c("GoA", "NCC","CCC", "SCC"),each = 3000)))%>%
  rename(alpha=tempalpha, beta = tempbeta)

region.lev <-c("GoA", "Northern CC", "Central CC", "Southern CC")
annual$region <-factor(annual$region, levels=region.lev) 
region.lev2 <-c("GoA", "NCC", "CCC", "SCC")


annual$region <- factor(annual$region, levels=region.lev) 
scaled.anomaly$region <-factor(scaled.anomaly$region, levels=region.lev2) 

```

Plots of the annual average model.

```{r seasonalANNUALplots, echo=FALSE}

ggplot(data = annual, aes(x = stand_bakun_annual, y = annual_PDO,col=period)) +
    facet_wrap(.~region, ncol = 4, scales='free') +
  geom_point(size=0.75,aes(col=period)) +
  geom_smooth(method = "lm", se = FALSE, aes(col=as.factor(period))) +
  scale_x_continuous(name = "Upwelling (Bakun 1Ëš 6-hourly)") +
  scale_color_manual(values =  col[1:3], labels=c('1967 - 1988', '1989 - 2013', '2014 - 2022'))+
  theme_bw()


ggplot(scaled.anomaly, aes(x = beta, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Slope (scaled anomaly)",
       y = "Posterior density")

ggplot(scaled.anomaly, aes(x = alpha, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Intercept (scaled anomaly)",
       y = "Posterior density")

```

### Winter Model

Fitting the winter seasonal model

```{r seasonalWINTER, include=FALSE}

winter <- climate_dat%>%filter(season=="Winter")%>%
  select(Year_lag, region, season, seasonal_mean, stand_bakun_seasonally,stand_bakun_annual,period, era.region,seasonal_PDO)%>%
    distinct()%>%
  filter(Year_lag<2023)


N <- length(winter$period)
NP <- 12
P<- as.numeric(as.factor(winter$era.region))
P2<- as.numeric(as.factor(winter$region))
K <- 1
x <- data.frame(winter$stand_bakun_seasonally)
y<-winter$seasonal_PDO

data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P2, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)

bhfit.pdo.winter <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))


data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)

bhfit.pdo.winter.era <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))

posterior<-data.frame(summary(bhfit.pdo.winter.era, prob=c(0.025, 0.25,0.75, 0.975, 0.1, 0.9))$summary)

alphaP<-posterior[1:12,]%>%
  add_column(region = rep(c("GoA", "NCC","CCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))

betaP<-posterior[13:24,]%>%
  add_column(region = rep(c("GoA", "NCC","CCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))
n<- 1000
scaled.anomaly <- NULL
for(i in 1:NP){
tempalpha <- rnorm(n, alphaP$mean[i],alphaP$sd[i])
tempbeta <- rnorm(n, betaP$mean[i],betaP$sd[i])
scaled.anomaly <-rbind(scaled.anomaly,cbind(tempalpha, tempbeta))
}

scaled.anomaly<- scaled.anomaly%>%
  bind_cols(period=rep(rep(c('1967 - 1988', '1989 - 2013', '2014 - 2022'), each = 1000),4),
            region = rep(rep(c("GoA", "NCC","CCC", "SCC"),each = 3000)))%>%
  rename(alpha=tempalpha, beta = tempbeta)
winter$region <-factor(winter$region, levels=region.lev) 
scaled.anomaly$region <-factor(scaled.anomaly$region, levels=region.lev2) 

```

Plots of the winter seasonal model.

```{r seasonalWINTERplots, echo=FALSE}
ggplot(data = winter, aes(x = stand_bakun_seasonally, y = seasonal_PDO,col=period)) +
    facet_wrap(.~region, ncol = 4, scales='free') +
  geom_point(size=0.75,aes(col=period)) +
  geom_smooth(method = "lm", se = FALSE, aes(col=as.factor(period))) +
  scale_x_continuous(name = "Upwelling (Bakun 1Ëš 6-hourly)") +
  scale_color_manual(values =  col[1:3], labels=c('1967 - 1988', '1989 - 2013', '2014 - 2022'))+
  theme_bw()


ggplot(scaled.anomaly, aes(x = beta, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Slope (scaled anomaly)",
       y = "Posterior density")

ggplot(scaled.anomaly, aes(x = alpha, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Intercept (scaled anomaly)",
       y = "Posterior density")
```

### Spring Model

Fitting the spring seasonal model

```{r seasonalSPRING, include=FALSE}

spring <- climate_dat%>%filter(season=="Spring")%>%
  select(Year_lag, region, season, seasonal_mean, stand_bakun_seasonally,stand_bakun_annual,period, era.region,seasonal_PDO)%>%
    distinct()%>%
  filter(Year_lag<2023)

N <- length(spring$period)
NP <- 12
P<- as.numeric(as.factor(spring$era.region))
P2<- as.numeric(as.factor(spring$region))
K <- 1
x <- data.frame(spring$stand_bakun_seasonally)
y<-spring$seasonal_PDO

data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P2, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)

bhfit.pdo.spring <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))


data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)

bhfit.pdo.spring.era <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))

posterior<-data.frame(summary(bhfit.pdo.spring.era, prob=c(0.025, 0.25,0.75, 0.975, 0.1, 0.9))$summary)

alphaP<-posterior[1:12,]%>%
  add_column(region = rep(c("GoA", "NCC", "CCC","SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))

betaP<-posterior[13:24,]%>%
  add_column(region = rep(c("GoA", "NCC","CCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))
n<- 1000
scaled.anomaly <- NULL
for(i in 1:NP){
tempalpha <- rnorm(n, alphaP$mean[i],alphaP$sd[i])
tempbeta <- rnorm(n, betaP$mean[i],betaP$sd[i])
scaled.anomaly <-rbind(scaled.anomaly,cbind(tempalpha, tempbeta))
}

scaled.anomaly<- scaled.anomaly%>%
  bind_cols(period=rep(rep(c('1967 - 1988', '1989 - 2013', '2014 - 2022'), each = 1000),4),
            region = rep(rep(c("GoA", "NCC","CCC", "SCC"),each = 3000)))%>%
  rename(alpha=tempalpha, beta = tempbeta)

spring$region <-factor(spring$region, levels=region.lev) 
scaled.anomaly$region <-factor(scaled.anomaly$region, levels=region.lev2) 

```

Spring model plots

```{r seasonalSPRINGplots, echo=FALSE}
ggplot(data = spring, aes(x = stand_bakun_seasonally, y =seasonal_PDO,col=period)) +
    facet_wrap(.~region, ncol = 4, scales='free') +
  geom_point(size=0.75,aes(col=period)) +
  geom_smooth(method = "lm", se = FALSE, aes(col=as.factor(period))) +
  scale_x_continuous(name = "Upwelling (Bakun 1Ëš 6-hourly)") +
  scale_color_manual(values =  col[1:3], labels=c('1967 - 1988', '1989 - 2013', '2014 - 2022'))+
  theme_bw()


ggplot(scaled.anomaly, aes(x = beta, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Slope",
       y = "Posterior density")

ggplot(scaled.anomaly, aes(x = alpha, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Intercept (scaled anomaly)",
       y = "Posterior density")
```

Comparing models using an "era" term

```{r pdoLOO, echo=FALSE, include= FALSE}

pdo.annual.era<-loo(extract_log_lik(bhfit.pdo.annual.era, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))
pdo.annual<-loo(extract_log_lik(bhfit.pdo.annual, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))

pdo.annual<-list(pdo.annual.era,pdo.annual)
loo.pdo.annual <- loo_compare(pdo.annual)

pdo.winter.era<-loo(extract_log_lik(bhfit.pdo.winter.era, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))
pdo.winter<-loo(extract_log_lik(bhfit.pdo.winter, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))

pdo.winter<-list(pdo.winter.era,pdo.winter)
loo.pdo.winter <- loo_compare(pdo.winter)


pdo.spring.era<-loo(extract_log_lik(bhfit.pdo.spring.era, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))
pdo.spring<-loo(extract_log_lik(bhfit.pdo.spring, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))

pdo.spring<-list(pdo.spring.era,pdo.spring)
loo.pdo.spring <- loo_compare(pdo.spring)

```

PDO Model Comparison

| Season     | Era Model elpd_diff | Region Model elpd_diff     |
| :---        |    :----:   |          ---: |
| Annual    | 0 (0) |  -434.2 (66.7)   |
| Winter | 0 (0) |-417.4 (68.0)     |
| Spring  | 0 (0)  | -438.7 (71.6)    |


#NPGO

## Seasonal Mean Models

These results utilize seasonal averagers rather than monthly means within a season. May be better for identifying trends that are not spuriously seasonal (i.e. changes in a given month) but tradeoff is less data and may miss some interesting dynamics as a result

### Annual Model

```{r NPGOseasonalANNUAL, include=FALSE}
annual <- climate_dat%>%
  select(Year_lag, region, stand_bakun_seasonally,stand_bakun_annual,period, era.region,annual_NPGO)%>%
    distinct()%>%
  filter(Year_lag<2023)

N <- length(annual$period)
NP <- 12
P<- as.numeric(as.factor(annual$era.region))
P2<- as.numeric(as.factor(annual$region))
K <- 1
x <- data.frame(annual$stand_bakun_annual)
y<-annual$annual_NPGO

data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P2, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)


bhfit.npgo.annual <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))

data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)


bhfit.npgo.annual.era <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))

posterior<-data.frame(summary(bhfit.npgo.annual.era, prob=c(0.025, 0.25,0.75, 0.975, 0.1, 0.9))$summary)

alphaP<-posterior[1:12,]%>%
  add_column(region = rep(c("GoA", "NCC","CCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))

betaP<-posterior[13:24,]%>%
  add_column(region = rep(c("GoA", "NCC","CCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))
n<- 1000
scaled.anomaly <- NULL
for(i in 1:NP){
tempalpha <- rnorm(n, alphaP$mean[i],alphaP$sd[i])
tempbeta <- rnorm(n, betaP$mean[i],betaP$sd[i])
scaled.anomaly <-rbind(scaled.anomaly,cbind(tempalpha, tempbeta))
}

scaled.anomaly<- scaled.anomaly%>%
  bind_cols(period=rep(rep(c('1967 - 1988', '1989 - 2013', '2014 - 2022'), each = 1000),4),
            region = rep(rep(c("GoA", "NCC","CCC", "SCC"),each = 3000)))%>%
  rename(alpha=tempalpha, beta = tempbeta)
annual$region <-factor(annual$region, levels=region.lev) 
scaled.anomaly$region <-factor(scaled.anomaly$region, levels=region.lev2) 

```

Plots of the annual average model.

```{r NPGOANNUALplots, echo=FALSE}
ggplot(data = annual, aes(x = stand_bakun_annual, y = annual_NPGO,col=period)) +
    facet_wrap(.~region, ncol = 4, scales='free') +
  geom_point(size=0.75,aes(col=period)) +
  geom_smooth(method = "lm", se = FALSE, aes(col=as.factor(period))) +
  scale_x_continuous(name = "Upwelling (Bakun 1Ëš 6-hourly)") +
  scale_color_manual(values =  col[1:3], labels=c('1967 - 1988', '1989 - 2013', '2014 - 2022'))+
  theme_bw()


ggplot(scaled.anomaly, aes(x = beta, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Slope (scaled anomaly)",
       y = "Posterior density")

ggplot(scaled.anomaly, aes(x = alpha, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Intercept (scaled anomaly)",
       y = "Posterior density")
```

### Winter Model

Fitting the winter seasonal model

```{r NPGOseasonalWINTER, include=FALSE}

winter <- climate_dat%>%filter(season=="Winter")%>%
  select(Year_lag, region, season, seasonal_mean, stand_bakun_seasonally,stand_bakun_annual,period, era.region,seasonal_NPGO)%>%
    distinct()%>%
  filter(Year_lag<2023)


N <- length(winter$period)
NP <- 12
P<- as.numeric(as.factor(winter$era.region))
P2<- as.numeric(as.factor(winter$region))
K <- 1
x <- data.frame(winter$stand_bakun_seasonally)
y<-winter$seasonal_NPGO

data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P2, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)


bhfit.npgo.winter <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))


data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)


bhfit.npgo.winter.era <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))

posterior<-data.frame(summary(bhfit.npgo.winter.era, prob=c(0.025, 0.25,0.75, 0.975, 0.1, 0.9))$summary)

alphaP<-posterior[1:12,]%>%
  add_column(region = rep(c("GoA", "NCC","CCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))

betaP<-posterior[13:24,]%>%
  add_column(region = rep(c("GoA", "NCC","CCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))
n<- 1000
scaled.anomaly <- NULL
for(i in 1:NP){
tempalpha <- rnorm(n, alphaP$mean[i],alphaP$sd[i])
tempbeta <- rnorm(n, betaP$mean[i],betaP$sd[i])
scaled.anomaly <-rbind(scaled.anomaly,cbind(tempalpha, tempbeta))
}

scaled.anomaly<- scaled.anomaly%>%
  bind_cols(period=rep(rep(c('1967 - 1988', '1989 - 2013', '2014 - 2022'), each = 1000),4),
            region = rep(rep(c("GoA", "NCC","CCC", "SCC"),each = 3000)))%>%
  rename(alpha=tempalpha, beta = tempbeta)

winter$region <-factor(winter$region, levels=region.lev) 
scaled.anomaly$region <-factor(scaled.anomaly$region, levels=region.lev2) 

```

Plots of the winter seasonal model.

```{r NPGOseasonalWINTERplots, echo=FALSE}
ggplot(data = winter, aes(x = stand_bakun_seasonally, y = seasonal_NPGO,col=period)) +
    facet_wrap(.~region, ncol = 4, scales='free') +
  geom_point(size=0.75,aes(col=period)) +
  geom_smooth(method = "lm", se = FALSE, aes(col=as.factor(period))) +
  scale_x_continuous(name = "Upwelling (Bakun 1Ëš 6-hourly)") +
  scale_color_manual(values =  col[1:3], labels=c('1967 - 1988', '1989 - 2013', '2014 - 2022'))+
  theme_bw()


ggplot(scaled.anomaly, aes(x = beta, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Slope (scaled anomaly)",
       y = "Posterior density")

ggplot(scaled.anomaly, aes(x = alpha, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Intercept (scaled anomaly)",
       y = "Posterior density")
```

### Spring Model

Fitting the spring seasonal model

```{r NPGOseasonalSPRING, include=FALSE}

spring <- climate_dat%>%filter(season=="Spring")%>%
  select(Year_lag, region, season, seasonal_mean, stand_bakun_seasonally,stand_bakun_annual,period, era.region,seasonal_NPGO)%>%
    distinct()%>%
  filter(Year_lag<2023)

N <- length(spring$period)
NP <- 12
P<- as.numeric(as.factor(spring$era.region))
P2<- as.numeric(as.factor(spring$region))
K <- 1
x <- data.frame(spring$stand_bakun_seasonally)
y<-spring$seasonal_NPGO

data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P2, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)

bhfit.npgo.spring <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))

data <- list(N = N, #total number of opservations
             NP=NP, #total number of time periods
             P = P, #time period pointer vector
             K = K,#number of covariates, starting with one but can add for final model structure
             x=x, #Upwelling
             y=y #response variable
)

bhfit.npgo.spring.era <- stan(
  file = here::here("Src/BayesianLinearHierarchicalModels.stan"),
  data = data,
  chains = n_chains,
  warmup = warmups,
  iter = total_iterations,
  cores = n_cores,
  refresh = 250,
  control = list(max_treedepth = max_treedepth,
                 adapt_delta = adapt_delta))


posterior<-data.frame(summary(bhfit.npgo.spring.era, prob=c(0.025, 0.25,0.75, 0.975, 0.1, 0.9))$summary)

alphaP<-posterior[1:12,]%>%
  add_column(region = rep(c("GoA", "NCC", "CCC","SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))

betaP<-posterior[13:24,]%>%
  add_column(region = rep(c("GoA", "NCC","CCC", "SCC"),each =3), 
             period=rep(c("1967 - 1988","1989 - 2013","2014 - 2022"),4))
n<- 1000
scaled.anomaly <- NULL
for(i in 1:NP){
tempalpha <- rnorm(n, alphaP$mean[i],alphaP$sd[i])
tempbeta <- rnorm(n, betaP$mean[i],betaP$sd[i])
scaled.anomaly <-rbind(scaled.anomaly,cbind(tempalpha, tempbeta))
}

scaled.anomaly<- scaled.anomaly%>%
  bind_cols(period=rep(rep(c('1967 - 1988', '1989 - 2013', '2014 - 2022'), each = 1000),4),
            region = rep(rep(c("GoA", "NCC","CCC", "SCC"),each = 3000)))%>%
  rename(alpha=tempalpha, beta = tempbeta)

spring$region <-factor(spring$region, levels=region.lev) 
scaled.anomaly$region <-factor(scaled.anomaly$region, levels=region.lev2) 

```

Spring model plots

```{r NPGOseasonalSPRINGplots, echo=FALSE}
ggplot(data = spring, aes(x = stand_bakun_seasonally, y =seasonal_NPGO,col=period)) +
    facet_wrap(.~region, ncol = 4, scales='free') +
  geom_point(size=0.75,aes(col=period)) +
  geom_smooth(method = "lm", se = FALSE, aes(col=as.factor(period))) +
  scale_x_continuous(name = "Upwelling (Bakun 1Ëš 6-hourly)") +
  scale_color_manual(values =  col[1:3], labels=c('1967 - 1988', '1989 - 2013', '2014 - 2022'))+
  theme_bw()


ggplot(scaled.anomaly, aes(x = beta, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Slope",
       y = "Posterior density")

ggplot(scaled.anomaly, aes(x = alpha, fill = period)) +
  theme_bw() +
  facet_wrap(.~region, ncol = 4, scales='free') +
  geom_density(alpha = 0.7) +
  scale_fill_manual(values = c(col[1], col[2], col[3]), labels=c("1967-1988", "1989-2013", "2014-2022")) +
  #theme(legend.title = element_blank(), legend.position = 'top', legend.key.size = unit(3, 'mm')) +
  geom_vline(xintercept = 0, lty = 2) +
  labs(x = "Intercept (scaled anomaly)",
       y = "Posterior density")
```


Comparing models using an "era" term

```{r npgoLOO, echo=FALSE, include= FALSE}

npgo.annual.era<-loo(extract_log_lik(bhfit.npgo.annual.era, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))
npgo.annual<-loo(extract_log_lik(bhfit.npgo.annual, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))

npgo.annual<-list(npgo.annual.era,npgo.annual)
loo.npgo.annual <- loo_compare(npgo.annual)

npgo.winter.era<-loo(extract_log_lik(bhfit.npgo.winter.era, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))
npgo.winter<-loo(extract_log_lik(bhfit.npgo.winter, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))

npgo.winter<-list(npgo.winter.era,npgo.winter)
loo.npgo.winter <- loo_compare(npgo.winter)


npgo.spring.era<-loo(extract_log_lik(bhfit.npgo.spring.era, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))
npgo.spring<-loo(extract_log_lik(bhfit.npgo.spring, parameter_name = c("alphaP","betaP","sigma"),merge_chains = TRUE))

npgo.spring<-list(npgo.spring.era,npgo.spring)
loo.npgo.spring <- loo_compare(npgo.spring)

```

NPGO Model Comparison

| Season     | Era Model elpd_diff | Region Model elpd_diff     |
| :---        |    :----:   |          ---: |
| Annual    | 0 (0) |  -442.5 (77.8)   |
| Winter | 0 (0) | -420.1 (70.5)     |
| Spring  | 0 (0)  | -16.0 (9.5)    |


## Questions / Thoughts

To Do: 

1) Examine Upwelling relationships with SLP, SSH, wind stress, and SST
Examine the relationship between SST and the same set of atmospheric variables (PDO, SLP, SSH, wind stress). Would we really expect different relationships with SLP given its reanalyses are what make up Bakun indices?

2) we could also compare these results to results with CUTI and BEUTI that use just the last two periods (CUTI and BEUTI account for more nuanced changes in cross and along shore wind; only data after 1988)

3) *plankton case study* I think that this paper would be more compelling if it had some degree of biology. Maybe we could bring in some of the Zoop CalCofi data as a case study within the larger regional analysis and link these changing relationships to an ecosystem response - it would also be a nice thing to build our way up the food web with the salmon/groundfish part of the project and still take a foodweb wide view that was initially in the proposal. Are there are plankton datasets in the Southern California Current and/or GoA we could use?

4) How should we think/talk about intercepts. To me slopes are more compelling...

## Interpretations
## NPGO

## PDO 
**Winter** across all regions, the 1967 - 1988 period shows the greatest difference in intercept with the 1989 - 2013 period where the most recent heat wave period actually falls between the two however slopes are much more consistent with substantial posterior overlap for all three periods in all regions.

**Spring** strong change in the slope of NCC during spring but less in other regions where it overlaps with the other two eras - this is consistent with both approaches to characterizing season.

The seasonal average model shows more of a difference for the SCC for the most recent heatwave period than the monthly mean model.

**Summer** Summer is pretty consistent in slop and intercept with the exception of the SCC intercept is different for the early and late periods compared to the middle.