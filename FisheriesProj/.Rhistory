library(dplyr)
library(reshape2)
library(bayesdfa)
library(MCMCvis)
#Organize SCC biology data
dat<- read.csv("data/biologydata_south.central_2023.csv")
n1 <- names(dat)[grepl('calcofi.',names(dat))]
n2 <- names(dat)[grepl('rreas.',names(dat))]
ids <- c(n1,n2,"ZALOPHUS.PUPCT","ZALOPHUS.PUPWT")
n3 <- names(dat)[grepl('SBRD.',names(dat))]
n4 <- names(dat)[grepl('ZALOPHUS.',names(dat))]
for(i in 1:ncol(dat)){
if(names(dat)[i] %in% ids){
dat[,i] <- log(dat[,i])
}
}
#dat<-dat%>%select(c(year,n4,n3,n1))
#### Running SCC  model####
dat.scc<-dat%>%select(c(year,n4,n1))
remelt = melt(dat.scc,id.vars = "year")
names(remelt)<-c("year","code","value")
Y <- dcast(remelt, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])
n_chains = 3
n_iter = 8000
options(mc.cores = parallel::detectCores())
# load environmental covariate data, and average over spring months to have one value per covar per year
nspp=dim(Y)[1]
nyear=dim(Y)[2]
ntrend=1
n_row=nspp*nyear
n_row_pro=ntrend*nyear
model_df = expand.grid(estimate_trend_ma = FALSE,
estimate_trend_ar = TRUE, est_nu = TRUE, estimate_process_sigma = c(TRUE, FALSE),
var_index = c("survey"), num_trends = 1:3,
elpd_loo = NA, se_elpd_loo=NA)
#dat<-dat%>%select(c(year,n4,n3,n1))
#### Running Full  model####
remelt = melt(dat.scc,id.vars = "year")
remelt = melt(dat.scc,id.vars = "year")
names(remelt)<-c("year","code","value")
Y <- dcast(remelt, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])
n_chains = 3
n_iter = 8000
options(mc.cores = parallel::detectCores())
# load environmental covariate data, and average over spring months to have one value per covar per year
nspp=dim(Y)[1]
nyear=dim(Y)[2]
ntrend=1
n_row=nspp*nyear
n_row_pro=ntrend*nyear
varIndx = c(rep(1,length(n4)),rep(2,length(n3)), rep(3, length(n2)), rep(4, length(n1)))
varIndx
model_df = expand.grid(estimate_trend_ma = FALSE,
estimate_trend_ar = TRUE, est_nu = TRUE, estimate_process_sigma = c(TRUE, FALSE),
var_index = c("survey"), num_trends = 1:3,
elpd_loo = NA, se_elpd_loo=NA)
model_df
fit.mod.best = fit_dfa(y = Y,
num_trends = 1,
iter=n_iter,
varIndx = varIndx,
chains=n_chains, estimate_nu=model_df$est_nu[1],
estimate_trend_ma = model_df$estimate_trend_ma[1],
estimate_trend_ar = model_df$estimate_trend_ar[1],
estimate_process_sigma = model_df$estimate_process_sigma[1],
seed=123)
#Organize SCC biology data
dat<- read.csv("data/biologydata_south.central_2023.csv")
n1 <- names(dat)[grepl('calcofi.',names(dat))]
n2 <- names(dat)[grepl('rreas.',names(dat))]
ids <- c(n1,n2,"ZALOPHUS.PUPCT","ZALOPHUS.PUPWT")
n3 <- names(dat)[grepl('SBRD.',names(dat))]
n4 <- names(dat)[grepl('ZALOPHUS.',names(dat))]
for(i in 1:ncol(dat)){
if(names(dat)[i] %in% ids){
dat[,i] <- log(dat[,i])
}
}
#### Running Full  model####
dat<-dat%>%select(c(year,n4,n3,n2,n1)) #just setting an order so we know how to set the variance index for each survey
remelt = melt(dat.scc,id.vars = "year")
names(remelt)<-c("year","code","value")
Y <- dcast(remelt, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])
n_chains = 3
n_iter = 8000
options(mc.cores = parallel::detectCores())
# load environmental covariate data, and average over spring months to have one value per covar per year
nspp=dim(Y)[1]
nyear=dim(Y)[2]
ntrend=1
n_row=nspp*nyear
n_row_pro=ntrend*nyear
model_df = expand.grid(estimate_trend_ma = FALSE,
estimate_trend_ar = TRUE, est_nu = TRUE, estimate_process_sigma = c(TRUE, FALSE),
var_index = c("survey"), num_trends = 1:3,
elpd_loo = NA, se_elpd_loo=NA)
varIndx = c(rep(1,length(n4)),rep(2,length(n3)), rep(3, length(n2)), rep(4, length(n1)))
fit.mod.best = fit_dfa(y = Y,
num_trends = 1,
iter=n_iter,
varIndx = varIndx,
chains=n_chains, estimate_nu=model_df$est_nu[1],
estimate_trend_ma = model_df$estimate_trend_ma[1],
estimate_trend_ar = model_df$estimate_trend_ar[1],
estimate_process_sigma = model_df$estimate_process_sigma[1],
seed=123)
#### Running Full  model####
dat<-dat%>%select(c(year,n4,n3,n2,n1)) #just setting an order so we know how to set the variance index for each survey
#### Running Full  model####
dat<-dat%>%select(c(year,n4,n3,n2,n1)) #just setting an order so we know how to set the variance index for each survey
remelt = melt(datc,id.vars = "year")
names(remelt)<-c("year","code","value")
Y <- dcast(remelt, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])
n_chains = 3
n_iter = 8000
options(mc.cores = parallel::detectCores())
# load environmental covariate data, and average over spring months to have one value per covar per year
nspp=dim(Y)[1]
nyear=dim(Y)[2]
ntrend=1
n_row=nspp*nyear
n_row_pro=ntrend*nyear
model_df = expand.grid(estimate_trend_ma = FALSE,
estimate_trend_ar = TRUE, est_nu = TRUE, estimate_process_sigma = c(TRUE, FALSE),
var_index = c("survey"), num_trends = 1:3,
elpd_loo = NA, se_elpd_loo=NA)
varIndx = c(rep(1,length(n4)),rep(2,length(n3)), rep(3, length(n2)), rep(4, length(n1)))
fit.mod.best = fit_dfa(y = Y,
num_trends = 1,
iter=n_iter,
varIndx = varIndx,
chains=n_chains, estimate_nu=model_df$est_nu[1],
estimate_trend_ma = model_df$estimate_trend_ma[1],
estimate_trend_ar = model_df$estimate_trend_ar[1],
estimate_process_sigma = model_df$estimate_process_sigma[1],
seed=123)
Y
#Organize SCC biology data
dat<- read.csv("data/biologydata_south.central_2023.csv")
n1 <- names(dat)[grepl('calcofi.',names(dat))]
n2 <- names(dat)[grepl('rreas.',names(dat))]
ids <- c(n1,n2,"ZALOPHUS.PUPCT","ZALOPHUS.PUPWT")
n3 <- names(dat)[grepl('SBRD.',names(dat))]
n4 <- names(dat)[grepl('ZALOPHUS.',names(dat))]
for(i in 1:ncol(dat)){
if(names(dat)[i] %in% ids){
dat[,i] <- log(dat[,i])
}
}
#### Running Full  model####
dat<-dat%>%select(c(year,n4,n3,n2,n1)) #just setting an order so we know how to set the variance index for each survey
remelt = melt(dat,id.vars = "year")
names(remelt)<-c("year","code","value")
Y <- dcast(remelt, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])
n_chains = 3
n_iter = 8000
options(mc.cores = parallel::detectCores())
# load environmental covariate data, and average over spring months to have one value per covar per year
nspp=dim(Y)[1]
nyear=dim(Y)[2]
ntrend=1
n_row=nspp*nyear
n_row_pro=ntrend*nyear
model_df = expand.grid(estimate_trend_ma = FALSE,
estimate_trend_ar = TRUE, est_nu = TRUE, estimate_process_sigma = c(TRUE, FALSE),
var_index = c("survey"), num_trends = 1:3,
elpd_loo = NA, se_elpd_loo=NA)
varIndx = c(rep(1,length(n4)),rep(2,length(n3)), rep(3, length(n2)), rep(4, length(n1)))
fit.mod.best = fit_dfa(y = Y,
num_trends = 1,
iter=n_iter,
varIndx = varIndx,
chains=n_chains, estimate_nu=model_df$est_nu[1],
estimate_trend_ma = model_df$estimate_trend_ma[1],
estimate_trend_ar = model_df$estimate_trend_ar[1],
estimate_process_sigma = model_df$estimate_process_sigma[1],
seed=123)
pars = rstan::extract(fit.mod.best$model)
r <- rotate_trends(fit.mod.best)
p <- plot_trends(r)
p
l <- plot_loadings(r,names=names)
l
is_converged(fit.mod.best)
is_converged(fit.mod.best, threshold = 1.05, parameters = c("sigma", "x", "Z")))
is_converged(fit.mod.best, threshold = 1.05, parameters = c("sigma", "x", "Z"))
is_converged(fit.mod.best, threshold = 1.05, parameters = c("x", "Z"))
#running the best model
varIndx = c(rep(1,length(n4)+length(n3)+length(n2)+length(n1))
#running the best model
varIndx = c(rep(1,length(n4)+length(n3)+length(n2)+length(n1)))
#running the best model
varIndx = c(rep(1,length(n4)+length(n3)+length(n2)+length(n1)))
fit.mod.best = fit_dfa(y = Y,
num_trends = 1,
iter=n_iter,
varIndx = varIndx,
chains=n_chains, estimate_nu=model_df$est_nu[1],
estimate_trend_ma = model_df$estimate_trend_ma[1],
estimate_trend_ar = model_df$estimate_trend_ar[1],
estimate_process_sigma = model_df$estimate_process_sigma[1],
seed=123)
pars = rstan::extract(fit.mod.best$model)
r <- rotate_trends(fit.mod.best)
p <- plot_trends(r)
p
l <- plot_loadings(r,names=names)
l
is_converged(fit.mod.best, threshold = 1.05, parameters = c("sigma", "x", "Z"))
pars = rstan::extract(fit.mod.best$model)
r <- rotate_trends(fit.mod.best)
p <- plot_trends(r)
p
l <- plot_loadings(r,names=names)
l
